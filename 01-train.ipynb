{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from models import create_fixed_input_shape_model, create_variable_input_shape_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (160, 160)\n",
    "NUM_CLASSES = 10\n",
    "train_dir = \"datasets/imagenette2/train\"\n",
    "test_dir = \"datasets/imagenette2/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Training a Fixed Input Shape Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augment_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_data_generator = data_augment_generator.flow_from_directory(\n",
    "    train_dir, batch_size=32, class_mode=\"categorical\", target_size=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_data_generator = data_generator.flow_from_directory(\n",
    "    test_dir, batch_size=64, class_mode=\"categorical\", target_size=IMAGE_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_fixed_input_shape_model(IMAGE_SIZE, NUM_CLASSES)\n",
    "model.compile(\n",
    "    optimizer=\"RMSProp\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    validation_data=test_data_generator,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"fixed-imagenette2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Training a Variable Input Shape Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableImageGenerator():\n",
    "    def __init__(self, directory, preprocessing_fn, batch_size=16, shuffle=False, max_dimension=None):        \n",
    "        self.directories = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.max_dimension = max_dimension\n",
    "        self.img_paths, self.class_labels = self._traverse(directory)\n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "\n",
    "        #index array for shuffling data\n",
    "        self.idx = np.arange(len(self.img_paths))\n",
    "    \n",
    "    def __len__(self):\n",
    "        #number of batches in an epoch\n",
    "        return int(np.ceil(len(self.img_paths) / float(self.batch_size)))\n",
    "\n",
    "    def _traverse(self, directory):\n",
    "        img_paths = []\n",
    "        class_labels = []\n",
    "\n",
    "        #create list of image file paths and class target labels\n",
    "        for class_label, class_dir in enumerate(sorted(os.listdir(directory))):\n",
    "            img_paths += [os.path.join(directory, class_dir, fn) for fn in os.listdir(os.path.join(directory, class_dir))]\n",
    "            class_labels += [class_label for _ in os.listdir(os.path.join(directory, class_dir))]\n",
    "\n",
    "        class_labels = np.array(class_labels)\n",
    "        class_one_hot_labels = np.zeros((class_labels.size, class_labels.max() + 1))\n",
    "        class_one_hot_labels[np.arange(class_labels.size), class_labels] = 1\n",
    "\n",
    "        return np.array(img_paths), class_one_hot_labels\n",
    "    \n",
    "    \n",
    "    def _load_img(self, img_path):\n",
    "        #load image from path and convert to array\n",
    "        img = load_img(img_path, color_mode='rgb', interpolation='nearest', target_size=None)\n",
    "        \n",
    "        #downsample image if above allowed size if specified\n",
    "        img_max_dimension = max(img.size) \n",
    "        if self.max_dimension:\n",
    "            if img_max_dimension > self.max_dimension:\n",
    "                new_dimension = tuple(dim * self.max_dimension // img_max_dimension for dim in img.size)\n",
    "                img = img.resize(size=new_dimension, resample=Image.BILINEAR)\n",
    "            \n",
    "        img = img_to_array(img) # convert PIL image to numpy array\n",
    "\n",
    "        return self.preprocessing_fn(img) # scale image values\n",
    "    \n",
    "    \n",
    "    def _pad_img(self, img, shape):\n",
    "        #pad images to match largest image in batch\n",
    "        width, height = shape\n",
    "        img_width, img_height, _ = img.shape\n",
    "\n",
    "        diff_w = ((width - img_width) // 2, ((width - img_width) // 2) + ((width - img_width) % 2))\n",
    "        diff_h = ((height - img_height) // 2, ((height - img_height) // 2) + ((height - img_height) % 2))\n",
    "\n",
    "        return np.pad(img, (diff_w, diff_h, (0, 0)), mode='constant', constant_values=0.)\n",
    "\n",
    "    def __call__(self):\n",
    "        #shuffle index\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idx)\n",
    "        \n",
    "        #generate batches\n",
    "        for batch_no in range(len(self)):\n",
    "            _img_paths = self.img_paths[self.idx[batch_no * self.batch_size:(batch_no + 1) * self.batch_size]]\n",
    "            img_classes = self.class_labels[self.idx[batch_no * self.batch_size:(batch_no + 1) * self.batch_size]]\n",
    "\n",
    "            imgs = [self._load_img(img_path) for img_path in _img_paths]\n",
    "            batch_max_dim = tuple(max([img.shape[i] for img in imgs]) for i in range(2))\n",
    "            imgs = np.array([self._pad_img(image, batch_max_dim) for image in imgs])\n",
    "\n",
    "            yield imgs, img_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = VariableImageGenerator(train_dir, preprocessing_fn=preprocess_input, batch_size=32, shuffle=True, max_dimension=160)\n",
    "test_generator = VariableImageGenerator(test_dir, preprocessing_fn=preprocess_input, batch_size=32, max_dimension=160)\n",
    "\n",
    "#convert generators into tf.data.Dataset objects for optimization with keras model fit method\n",
    "train_dataset = Dataset.from_generator(train_generator, (tf.float32, tf.int32), (tf.TensorShape([None, None, None, 3]), tf.TensorShape([None, NUM_CLASSES])))\n",
    "test_dataset = Dataset.from_generator(test_generator, (tf.float32, tf.int32), (tf.TensorShape([None, None, None, 3]), tf.TensorShape([None, NUM_CLASSES])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_variable_input_shape_model(NUM_CLASSES)\n",
    "model.compile(\n",
    "    optimizer=\"RMSProp\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_data_generator,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"variable-imagenette2.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf398a4fc88ef0ce957c80d144ba01976e3d1e8f3bdb19ac842cbbdcb5b0665d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
